#!/usr/bin/env python

# load default python packages
import logging, optparse, sys, glob, gzip, collections, copy, gzip, os, doctest, re
from os.path import *
from collections import defaultdict

try:
  from lxml import etree
except ImportError:
    # Python 2.5
    print "py 2.5 fallback etree"
    import xml.etree.cElementTree as etree

# add <scriptDir>/lib/ to package search path
sys.path.insert(0, join(dirname(abspath(__file__)), "lib"))

import pubGeneric, maxCommon, pubConf, maxbio

# example file /hive/data/outside/pdb/aa/pdb1aa0.ent.gz

pdbHeaders = ["acc", "isMain", "authors", "title", "ref", "issn", "pmid", "doi"]
pdbToHeader = {'AUTH' : "authors", "TITL" : "title", "REFN": "issn", "PMID":"pmid", "DOI":"doi", "REF":"ref", "isMain":"isMain", "acc": "acc"}
PdbRefRec  = collections.namedtuple("pdbRef", pdbHeaders)

def parsePdbRefLine(data, line):
    " add line to data dict "
    keyword, entry = line[12:16].strip(), line[19:].strip()
    if keyword in data:
        data[keyword] = data[keyword]+" "+entry
    else:
        data[keyword] = entry

def parsePdb(pdbDir, outDir):
    " write pdb.tab to outDir, parsing an ftp mirror from PDB "
    # get list of infnames
    if isdir(pdbDir):
        logging.info("Scanning for input files in %s" % pdbDir)
        inDirs = [d for d in glob.glob(pdbDir+"/*") if isdir(d)]
        inFnames = [] 
        for inDir in inDirs:
            dirFnames = glob.glob(inDir+"/*.ent.gz")
            inFnames.extend(dirFnames)
        logging.info("Found %d input files under %s" % (len(inFnames), pdbDir))
    elif isfile(pdbDir):
        inFnames = [pdbDir]
    else:
        raise Exception("pdbDir %s does not exist" % pdbDir)

    # write headers and open outfile
    outFname = join(outDir, "pdb.tab")
    logging.info("Writing to %s" % outFname)
    ofh = open(outFname, "w")
    ofh.write("\t".join(pdbHeaders))
    ofh.write("\n")

    tp = maxCommon.ProgressMeter(len(inFnames))
    for inFname in inFnames:
        logging.debug("Parsing %s" % inFname)
        ifh = gzip.open(inFname)
        refs = []
        refData = {}
        for line in ifh:
            if line.startswith("HEADER "):
                acc = line.split()[-1]

            if line.startswith("JRNL"):
                refData["isMain"]="1"
                refData["acc"] = acc
                parsePdbRefLine(refData, line)

            elif line.startswith("REMARK   1 "):
                if line[11:].startswith("REFERENCE"):
                    refs.append(refData)
                    refData = {}
                    refData["isMain"] = "0"
                    refData["acc"] = acc
                    continue
                parsePdbRefLine(refData, line)
        refs.append(refData)

        # translate keys from PDB to our own ones and write to outfile
        newRefs = []
        for ref in refs:
            if '' in ref:
                del ref['']
            if 'EDIT' in ref:
                del ref['EDIT']
            if 'PUBL' in ref:
                del ref['PUBL']
            if 'REFE' in ref: # looks like a typo in /hive/data/outside/pdb/o9/pdb1o91.ent.gz
                logging.warn("REFE typo ignored")
                del ref['REFE']
            newRef = {}
            for k, v, in ref.iteritems():
                newRef[pdbToHeader[k]] = v
            for h in pdbHeaders:
                if not h in newRef:
                    newRef[h] = ""
            newRef["issn"] = newRef["issn"].replace("ISSN ","")
            row = PdbRefRec(**newRef)
            ofh.write("\t".join(row))
            ofh.write("\n")

        tp.taskCompleted()
        

# UNIPROT PARSING 

# remove these PMIDs from all evidences
pmidBlackList = set([17344846]) # high-throughput study

# only parse these feature types
featTypes = {
    "sequence variant": "variant",
    "mutagenesis site": "mutagen",
    "modified residue": "modif",
    "cross-link": "cross-link",
    "region of interest": "interest",
    "short sequence motif": "motif",
    "metal ion-binding site": "ion-binding",
    "site": "site",
    "topological domain" : "topo",
    "transmembrane region" : "transmembr",
    "disulfide bond" : "disulf bond",
    "glycosylation site" : "glyco",
    "binding site" : "bind",
    "active site" : "enzyme act site",
    "signal peptide" : "signal pep",
    "transit peptide" : "trans pep",
    "calcium-binding region" : "calcium bind",
    "lipid moiety-binding region" : "lipid",
    "propeptide" : "propep",
    "intramembrane region" : "intramembr",
    "peptide" : "peptide",
    "nucleotide phosphate-binding region" : "nucl phos bind"
}

# main record info
entryHeaders = ["dataset", "acc", "mainIsoAcc", "orgName", "orgCommon", "taxonId", "name", "accList", \
    "protFullNames", "protShortNames", "protAltNames", "geneName", "geneSynonyms", "isoNames", \
    "geneOrdLocus", "geneOrf", \
    "hugo", "refSeq", "ncbiGene", "ensemblGene", "ensemblProt", "embl", "pdb", "uniGene", "omim",\
    "isoIds", "isoSeqs"]
EntryRec = collections.namedtuple("uprec", entryHeaders)

# disease associated mutation
mutHeaders = ["acc", "mainIsoAcc", "varId", "featType", "shortFeatType", "begin", "end", "origAa", "mutAa", "dbSnpId", "disRelated", "disease", "pmid", "comment"]
MutRec = collections.namedtuple("mutrec", mutHeaders)

# references from record
refHeaders = ["name", "citType", "year", "journal", "vol", "page", \
        "title", "authors", "doi", "pmid", "scopeList"]
RefRec = collections.namedtuple("refRec", refHeaders)
emptyRef = dict(zip(refHeaders, len(refHeaders)*[""]))

def strip_namespace_inplace(etree, namespace=None,remove_from_attr=True):
    """ Takes a parsed ET structure and does an in-place removal of all namespaces,
        or removes a specific namespacem (by its URL).
        
        Can make node searches simpler in structures with unpredictable namespaces
        and in content given to be non-mixed.

        By default does so for node names as well as attribute names.       
        (doesn't remove the namespace definitions, but apparently
         ElementTree serialization omits any that are unused)

        Note that for attributes that are unique only because of namespace,
        this may attributes to be overwritten. 
        For example: <e p:at="bar" at="quu">   would become: <e at="bar">

        I don't think I've seen any XML where this matters, though.
    """
    if namespace==None: # all namespaces                               
        for elem in etree.getiterator():
            tagname = elem.tag
            if not isinstance(elem.tag, basestring):
                continue
            if tagname[0]=='{':
                elem.tag = tagname[ tagname.index('}',1)+1:]

            if remove_from_attr:
                to_delete=[]
                to_set={}
                for attr_name in elem.attrib:
                    if attr_name[0]=='{':
                        old_val = elem.attrib[attr_name]
                        to_delete.append(attr_name)
                        attr_name = attr_name[attr_name.index('}',1)+1:]
                        to_set[attr_name] = old_val
                for key in to_delete:
                    elem.attrib.pop(key)
                elem.attrib.update(to_set)

    else: # asked to remove specific namespace.
        ns = '{%s}' % namespace
        nsl = len(ns)
        for elem in etree.getiterator():
            if elem.tag.startswith(ns):
                elem.tag = elem.tag[nsl:]

            if remove_from_attr:
                to_delete=[]
                to_set={}
                for attr_name in elem.attrib:
                    if attr_name.startswith(ns):
                        old_val = elem.attrib[attr_name]
                        to_delete.append(attr_name)
                        attr_name = attr_name[nsl:]
                        to_set[attr_name] = old_val
                for key in to_delete:
                    elem.attrib.pop(key)
                elem.attrib.update(to_set)


def parseHumDiseases(fname):
    " parse the file humanDiseases.txt from uniprot to resolve disease IDs to disease names "

def findSaveList(el, path, dataDict, key, attribKey=None, attribVal=None, useAttrib=None):
    " find all text of subelemets matching path with given attrib and save into dataDict with key"
    l = []
    for se in el.findall(path):
        if attribKey!=None and se.attrib.get(attribKey, None)!=attribVal:
            continue
        if useAttrib:
            val = se.attrib[useAttrib]
        else:
            val = se.text
        l.append(val)
    s = "|".join(l)
    dataDict[key] = s

def openOutTabFile(subDir, outName, headers):
    " create outdir and open outfile, write headers "
    #subDir = join(outDir, outSubDir) 
    if not isdir(subDir):
        logging.info("Creating dir %s" % subDir)
        os.makedirs(subDir)
    outPath = join(subDir, outName)
    logging.info("Writing output to %s" % outPath)
    ofh = open(outPath, "w")
    ofh.write("\t".join(headers)+"\n")
    return ofh

def findDiseases(text):
    """ find disease codes in text, return as a set of disease codes 
    >>> findDiseases("Defects in HAL are the cause of histidinemia (HISTID) ")
    set(['HISTID'])
    """
    words = phrase.split()
    for m in re.finditer("[( .;]([A-Z0-9-]+)[) .;]", text):
        if m.

#def findDiseases(text):
#    """ find disease codes and their names in text, return as dict code -> name 
#    >>> findDiseases("Defects in CEACAM16 are the cause of deafness autosomal dominant type 4B (DFNA4B) [MIM:614614].")
#    {'DFNA4B': 'deafness autosomal dominant type 4B'}
#    >>> findDiseases("Defects in ALX4 are the cause of parietal foramina 2 (PFM2) [MIM:609597]; also known as foramina parietalia permagna (FPP). PFM2 is an autosomal dominant disease characterized by oval defects of the parietal bones caused by deficient ossification around the parietal notch, which is normally obliterated during the fifth fetal month. PFM2 is also a clinical feature of Potocki-Shaffer syndrome.")
#    {'PFM2': 'parietal foramina 2', 'FPP': 'foramina parietalia permagna'}
#
#    # disease is only one word, but long enough
#    >>> findDiseases("Defects in HAL are the cause of histidinemia (HISTID) ")
#    {'HISTID': 'histidinemia'}
#    """
#    result = {}
#    phrases = re.split("[;.] ", text)
#    notDisease = set(["of", "with", "to", "as", "or", "also", "in"])
#
#    for phrase in phrases:
#        words = phrase.split()
#        revWords = reversed(words)
#
#        grabWords = False
#        disWords = []
#        disCode = None
#        # go backwords over words and look for acronym, then grab all words before that
#        # until we find a common English word
#        for word in revWords:
#            m = re.match("[(]([A-Z0-9-]+)[)]", word)
#            if m!=None:
#                disCode = m.group(1)
#                grabWords = True
#                continue
#
#            if word in notDisease and (len(disWords)>1 or len("".join(disWords))>=9):
#                disName = " ".join(list(reversed(disWords)))
#                if disCode==None:
#                    logging.debug("Found disease %s, but no code for it" % disName)
#                    continue
#                result[disCode] = disName
#                disCode = None
#                disWords = []
#                grabWords = False
#
#            if grabWords:
#                disWords.append(word)
#
#    return result

#def parseDiseaseComment(entryEl):
#    """ return two dicts 
#    one with evidence code -> disease code
#    one with disease code -> disease name 
#    """
#    disRefs = {}
#    disCodes = {}
#    for commentEl in entryEl.findall("comment"):
#        textEl = commentEl.find("text")
#        if commentEl.attrib["type"]=="disease":
#            refStr = commentEl.attrib.get("evidence", None)
#            # website xml is different, has evidence attribute on text element
#            if refStr==None:
#                refStr = textEl.attrib.get("evidence", None)
#                if refStr==None:
#                    continue
#
#            refs = refStr.split(" ")
#
#            text = textEl.text
#            logging.debug("Disease comment: %s, evidence %s" % (text, refStr))
#            disCodes.update(findDiseases(text))
#
#            for refId in refs:
#                disRefs[refId] = disCodes
#
#    logging.debug("Found disease evidences: %s" % disRefs)
#    logging.debug("Found disease names: %s" % disCodes)
#    return disRefs, disCodes

def parseDiseaseComment(entryEl):
    """ return dict
    with evidence code -> disease code
    """
    disRefs = {}
    disCodes = {}
    for commentEl in entryEl.findall("comment"):
        textEl = commentEl.find("text")
        if commentEl.attrib["type"]=="disease":
            refStr = commentEl.attrib.get("evidence", None)
            # website xml is different, has evidence attribute on text element
            if refStr==None:
                refStr = textEl.attrib.get("evidence", None)
                if refStr==None:
                    continue

            refs = refStr.split(" ")

            text = textEl.text
            logging.debug("Disease comment: %s, evidence %s" % (text, refStr))
            disCodes.update(findDiseases(text))

            for refId in refs:
                disRefs[refId] = disCodes

    logging.debug("Found disease evidences: %s" % disRefs)
    logging.debug("Found disease names: %s" % disCodes)
    return disRefs, disCodes

def parseIsoforms(acc, mainSeq, entryEl, isoSeqs):
    " parse sequences of isoforms, returns lists: isoIds, isoNames, seqs "
    isoDefined = False
    isoIds = []
    isoNames = []
    seqs = []
    for isoEl in entryEl.findall("comment/isoform"):
        isoDefined = True
        # get id
        idEl = isoEl.find("id")
        isoId = idEl.text

        # get names (just as gene synonyms)
        for nameEl in isoEl.find("name"):
            isoNames.append(nameEl.text)
        seqEl = isoEl.find("sequence")

        # get sequences
        seqType = seqEl.attrib["type"]
        if seqType=="displayed":
            seqs.append(mainSeq)
            isoIds.append(isoId)
        elif seqType=="external":
            pass # weird anyways
        else:
            if isoId not in isoSeqs:
                logging.debug("sequence %s does not exist" % isoId)
            else:
                seqs.append(isoSeqs[isoId])
                isoIds.append(isoId)

    if not isoDefined:
        isoIds = [acc]
        seqs = [mainSeq]

    #if len(seqs)!=len(isoIds):
        #print seqs, isoIds
    assert(len(seqs)==len(isoIds))

    return isoIds, isoNames, seqs

def parseDbRefs(entryEl):
    " return dict with db -> id (various special cases) "
    dbRefs = defaultdict(set)
    for dbRefEl in entryEl.findall("dbReference"):
        db = dbRefEl.attrib["type"]
        id = dbRefEl.attrib["id"]
        dbRefs[db].add(id)
        propEls = dbRefEl.findall("property")
        for propEl in propEls:
            propType = propEl.attrib["type"]
            propDb = db
            if (db, propType) ==("RefSeq", "nucleotide sequence ID"):
                id = propEl.attrib["value"]
                propDb = "refseqNucl"
            elif db=="HGNC" and propType=="gene designation":
                id = propEl.attrib["value"]
                propDb = "hgncGene"
            elif db=="Ensembl" and propType=="gene ID":
                id = propEl.attrib["value"]
                propDb = "ensemblGene"
            elif db=="Ensembl" and propType=="protein sequence ID":
                id = propEl.attrib["value"]
                propDb = "ensemblProt"
            else:
                id = dbRefEl.attrib["id"]
            dbRefs[propDb].add(id)

    result = {}
    for db, valList in dbRefs.iteritems():
        result[db] = "|".join(valList)
        
    logging.debug("dbRefs: %s" % result)
    return result

def splitAndResolve(disName, disCodes, splitWord):
    subDises = disName.split(splitWord)
    newDises = []
    for subDis in subDises:
        subDis = subDis.strip()
        if subDis in disCodes:
            newDises.append(disCodes[subDis])
        else:
            newDises.append(subDis)
    disName = "|".join(newDises)
    return disName

def parseFeatDesc(text, disCodes):
    """ return tuple: (disease name, dbSnpId, otherComments)
    >>> parseFeatDesc("In sporadic cancers; somatic mutation; dbSNP:rs11540654.", {})
    ('sporadic cancers', 'rs11540654', 'somatic mutation')
    >>> parseFeatDesc("In RIEG1; pointless comment", {"RIEG1" : "Axel-Riegerfeldt syndrome"})
    ('Axel-Riegerfeldt syndrome', '', 'pointless comment')
    """
    # find disease name and try to resolve via disCodes
    logging.debug("Feature description: %s (codes: %s)" % (text, disCodes))
    text = text.strip(".").strip()
    parts = text.split("; ")
    disName = ""
    comments = []
    for part in parts:
        part = part.replace("a patient with", "")
        part = part.replace("in a ", "in ")
        partLow = part.lower()
        if partLow.startswith("in ") and "dbSNP" not in part and "allele" not in part:
            disName = " ".join(part.split()[1:])
            # some entries contain two disease names
            if " and " in disName:
                disName = splitAndResolve(disName, disCodes, " and ")
            #if "," in disName:
                #disName = splitAndResolve(disName, disCodes, ",")
        else:
            if "dbSNP" not in part:
                comments.append(part)
                    
    if disName in disCodes:
        disName = disCodes[disName]

    if disName.startswith("an ") or disName.startswith("a "):
        disName = " ".join(disName.split(" ")[1:])

    # find snpId
    snpId = ""
    for m in re.finditer("dbSNP:(rs[0-9]+)", text):
        if m!=None:
            #assert(snpId=="")
            snpId = m.group(1)

    logging.debug("Disease: %s, snpId: %s" % (disName, snpId))
    return disName, snpId, "; ".join(comments)


ignoredTypes = collections.Counter()

def parseVariantFeatures(entryEl, disRefs, disCodes, evidPmids, mainIsoAcc):
    " go over features and yield mutation records "

    acc = entryEl.find("accession").text

    mutations = []
    for featEl in entryEl.findall("feature"):
        featType = featEl.attrib["type"]
        if featType not in featTypes:
            ignoredTypes[featType] += 1 
            continue
        shortFeatType = featTypes[featType]
        logging.debug("type: %s" % featType)

        varId = featEl.attrib.get("id", "")
        logging.debug("Variant ID %s" % varId)

        origEl = featEl.find("original")
        if origEl==None:
            #logging.debug("No original residue")
            #continue
            orig = ""
        else:
            orig = origEl.text

        varEl = featEl.find("variation")
        if varEl==None:
            variant = ""
        else:
            variant = varEl.text
            logging.debug("residue change: %s->%s" % (orig, variant))

        posEl = featEl.find("location/position")
        if posEl!=None:
            begin = posEl.attrib["position"]
            end = str(int(begin)+1)
        else:
            beginEl = featEl.find("location/begin")
            begin = beginEl.attrib.get("position", None)
            if begin==None:
                logging.debug("Unknown start, skipping a feature")
                continue
            endEl = featEl.find("location/end")
            end = endEl.attrib.get("position", None)
            if end==None:
                logging.debug("Unknown end, skipping a feature")
                continue
            end = str(int(end)+1)

        desc = featEl.attrib.get("description", None)
        if desc==None:
            #logging.debug("No description")
            #continue
            desc = ""
        if "sulfinic" in desc:
            shortFeatType = "sulfo"

        descWords = desc.split()
        if len(descWords)>0:
            desc1 = descWords[0].lower()
            if "phos" in desc1:
                shortFeatType = "phos"
            elif "acetyl" in desc1:
                shortFeatType = "acetyl"
            elif "methyl" in desc1:
                shortFeatType = "methyl"
            elif "lipo" in desc1:
                shortFeatType = "lipo"
            elif "hydroxy" in desc1:
                shortFeatType = "hydroxy"
            elif "nitro" in desc1:
                shortFeatType = "nitro"

        evidStr = featEl.attrib.get("evidence", "")
        logging.debug("variant pos %s-%s, desc %s, evidence %s" % (begin, end, desc, evidStr))
        desc = desc.strip("() ")
        #if desc=="":
            #logging.debug("No description")
            #continue
        #if evidStr==None:
            #logging.debug("No evidence")
            #continue
        evidList = evidStr.split()

        #disCode = disRefs[evidId]
        disName, snpId, comments = parseFeatDesc(desc, disCodes)

        varPmids = []
        diseaseRelated = "noEvidence"
        for evidId in evidList:
            if evidId in disRefs:
                diseaseRelated="disRelated"
            else:
                diseaseRelated="notDisRelated"
                logging.debug("evidence is not a disease evidence or blacklisted, check description")
                #if "sample" in desc or "cancer" in desc or varType=="mutagenesisSite":
                    #disName, snpId, comments = parseFeatDesc(desc, disCodes)
                #else:
                    #logging.debug("could not find word 'sample' in description")
                    #continue

            #if not evidId in evidPmids:
                #logging.debug("No PMID for this evidence")
                #continue
            pmids = evidPmids.get(evidId, [])
            assert(len(pmids)<=1)
            if len(pmids)>0:
                pmid = list(pmids)[0]
                varPmids.append(pmid)

        if len(varPmids)==1 and set(varPmids).intersection(pmidBlackList)==len(varPmids):
            logging.debug("only blacklist pmids, skipping feature")

        mut = MutRec(acc, mainIsoAcc, varId, featType, shortFeatType, begin, end, orig, variant, snpId, diseaseRelated, disName, ",".join(varPmids), comments)
        logging.debug("Accepted variant: %s" % str(mut))

        # rewrite disulfide bonds to two separate features, one for each cysteine involved
        if featType=="disulfide bond":
            end = mut.end
            mut1 = mut._replace(end=str(int(mut.begin)+1), comment=mut.comment+"; disulfide bond to position %s" % mut.end)
            yield mut1
            mut2 = mut._replace(begin=str(int(mut.end)-1), comment=mut.comment+"; disulfide bond to position %s" % mut.begin)
            yield mut2
        else:
            yield mut

def parseEvidence(entryEl):
    " return a dict with evidCode -> PMID "
    result = {}
    for evidEl in entryEl.findall("evidence"):
        evidCode = evidEl.attrib["key"]
        for dbRefEl in evidEl.findall("source/dbReference"):
            dbType = dbRefEl.attrib["type"]
            if dbType=="PubMed":
                pmid = dbRefEl.attrib["id"]
                #if pmid in pmidBlackList:
                    #continue
                result.setdefault(evidCode, [])
                result[evidCode].append(pmid)
    return result
    
def parseVariants(entryEl, mainIsoAcc):
    " return MutRecs with disease associated variants "
    disRefs, disCodes = parseDiseaseComment(entryEl)

    #if len(disRefs)==0:
        #logging.debug("No disease evidence")
        #return []
    acc = entryEl.find("accession").text
    logging.debug("Diseases in %s" % acc)

    evidPmids = parseEvidence(entryEl)
    mutRecs = list(parseVariantFeatures(entryEl, disRefs, disCodes, evidPmids, mainIsoAcc))
    return mutRecs

def parseRecInfo(entryEl, entry, isoSeqs):
    """parse uniprot general record info into entry dict
    use isoform sequences from isoSeqs
    only process certain taxonIds
    """
    dataset = entryEl.attrib["dataset"]
    entry["dataset"] = dataset

    findSaveList(entryEl, "name", entry, "name")
    findSaveList(entryEl, "accession", entry, "accList")
    entry["acc"] = entry["accList"].split("|")[0]

    findSaveList(entryEl, "protein/recommendedName/fullName", entry, "protFullNames")
    findSaveList(entryEl, "protein/recommendedName/shortName", entry, "protShortNames")
    findSaveList(entryEl, "protein/alternativeName/fullName", entry, "protAltNames")
    findSaveList(entryEl, "gene/name", entry, "geneName", attribKey="type", attribVal="primary")
    findSaveList(entryEl, "gene/name", entry, "geneSynonyms", attribKey="type", attribVal="synonym")
    findSaveList(entryEl, "gene/name", entry, "geneOrdLocus", attribKey="type", attribVal="ordered locus")
    findSaveList(entryEl, "gene/name", entry, "geneOrf", attribKey="type", attribVal="ORF")
    findSaveList(entryEl, "organism/name", entry, "orgName", attribKey="type", attribVal="scientific")
    findSaveList(entryEl, "organism/name", entry, "orgCommon", attribKey="type", attribVal="common")
    findSaveList(entryEl, "organism/dbReference", entry, "taxonId", useAttrib="id")
    findSaveList(entryEl, "comment/isoform/id", entry, "isoIds")
    findSaveList(entryEl, "comment/isoform/name", entry, "isoNames")

    mainSeq = entryEl.find("sequence").text
    isoIds, isoNames, seqs = parseIsoforms(entry["acc"], mainSeq, entryEl, isoSeqs)
    dbRefs = parseDbRefs(entryEl)
    entry["mainIsoAcc"] = isoIds[0]

    entry["hugo"] = dbRefs.get("hgncGene", "")
    entry["refSeq"] = dbRefs.get("refseqNucl", "")
    entry["ensemblProt"] = dbRefs.get("ensemblProt", "")
    entry["ensemblGene"] = dbRefs.get("ensemblGene", "")
    entry["ncbiGene"] = dbRefs.get("GeneId", "")
    entry["uniGene"] = dbRefs.get("UniGene", "")
    entry["omim"] = dbRefs.get("MIM", "")
    entry["embl"] = dbRefs.get("EMBL", "")
    entry["pdb"] = dbRefs.get("PDB", "")
        
    entry["isoIds"]="|".join(isoIds)
    entry["isoSeqs"]="|".join(seqs)
    entry["isoNames"]="|".join(isoNames)

    entryRow = EntryRec(**entry)
    return entryRow

def parseRefInfo(entryEl, recName):
    for refEl in entryEl.findall("reference"):
        ref = copy.copy(emptyRef)
        ref["name"] = recName
        citEl = refEl.find("citation")
        ref["citType"] = citEl.attrib["type"]
        year = citEl.attrib.get("date", "")
        ref["year"] = year.split("-")[0]
        ref["journal"] = citEl.attrib.get("name", "")
        if ref["journal"]=="":
            ref["journal"] = citEl.attrib.get("db", "") # for submissions
        ref["vol"] = citEl.attrib.get("volume", "")
        ref["page"] = citEl.attrib.get("first", "")
        for titleEl in citEl.findall("title"):
            ref["title"] = titleEl.text
        authorList = []
        for personEl in citEl.findall("authorList/person"):
            if "name" in personEl.attrib:
                name = personEl.attrib["name"]
                name = name.replace(" ", ",", 1)
                authorList.append(name)
        ref["authors"]=";".join(authorList)
        for dbRefEl in citEl.findall("dbReference"):
            if "type" in dbRefEl.attrib:
                if dbRefEl.attrib["type"]=="DOI":
                    ref["doi"] = dbRefEl.attrib["id"]
                if dbRefEl.attrib["type"]=="PubMed":
                    ref["pmid"] = dbRefEl.attrib["id"]

        findSaveList(refEl, "scope", ref, "scopeList")
        refRow = RefRec(**ref)
        yield refRow

def readIsoforms(inDir):
    " return all isoform sequences as dict isoName (eg. P48347-2) -> sequence "
    isoFname = join(inDir, "uniprot_sprot_varsplic.fasta.gz")
    isoFile = gzip.open(isoFname)
    logging.info("reading isoform sequences from %s" % isoFname)
    isoSeqs = maxbio.parseFastaAsDict(isoFile)
    result = {}
    seqNames = []
    for id, seq in isoSeqs.iteritems():
        idParts = id.split("|")
        isoName = idParts[1]
        result[isoName] = seq
        seqNames.append(idParts[2].split()[0])
    logging.info("Found %d isoform sequences" % len(result))
    return result, len(set(seqNames))


def writeFaSeqs(entry, faFiles, allVariants=False):
    """ write main sequence to faFile with the right taxonId 
    base sequence always has accession as ID 
    """
    #seqIds = entry.isoIds.split("|")
    if allVariants:
        seqIds = entry.isoIds.split("|")
        seqs = entry.isoSeqs.split("|")
    else:
        seqIds = [entry.acc]
        seqs   = [entry.isoSeqs.split("|")[0]]
    taxonId = entry.taxonId
    ofh = faFiles[taxonId]
    #for seqId, seq in zip(seqIds, seqs):
        #ofh.write(">%s\n%s\n" % (seqId, seq))
    c = 0
    for seqId, seq in zip(seqIds, seqs):
        if c==0 and allVariants:
            seqId = entry.acc
        ofh.write(">%s\n%s\n" % (seqId, seq))
        c+=1

def openFaFiles(taxonIds, outDir, outPrefix, seqType="base"):
    faFiles = {}
    for taxonId in taxonIds:
        taxonId = str(taxonId)
        seqQual = ""
        if seqType!="base":
            seqQual = "."+seqType
        faFname = join(outDir, outPrefix+"."+taxonId+seqQual+".fa.gz")
        faFiles[taxonId] = gzip.open(faFname, "w")
        logging.info("Writing fasta seqs for taxon %s to %s (seqType: %s)" % (taxonId, faFname, seqType))
    return faFiles

def parseUniprot(inDir, outDir, taxonIds):
    " parse uniprot, write records and refs to outdir "

    if options.parse:
        fname = options.parse
        logging.info("Debug parse of %s" % fname)
        xmlFile = open(fname)
        isoSeqs, recCount = {}, 1
        outDir = "."
        outPrefix = "temp"
    else:
        isoSeqs, recCount = readIsoforms(inDir)
        xmlFile = gzip.open(join(inDir, "uniprot_sprot.xml.gz"))
        logging.info("Parsing main XML file %s" % xmlFile.name)
        outPrefix = "uniprot"

    entryOf = openOutTabFile(outDir, outPrefix+".tab", entryHeaders)
    refOf = openOutTabFile(outDir, outPrefix+".refs.tab", refHeaders)
    mutOf = openOutTabFile(outDir, outPrefix+".mut.tab", mutHeaders)

    # base and variant sequence filehandles
    faFiles = openFaFiles(taxonIds, outDir, outPrefix)
    varFaFiles = openFaFiles(taxonIds, outDir, outPrefix, "var")

    emptyEntry = dict(zip(entryHeaders, len(entryHeaders)*[""]))

    pm = maxCommon.ProgressMeter(550000)
    for _, entryEl in etree.iterparse(xmlFile, tag='{http://uniprot.org/uniprot}entry'):
        strip_namespace_inplace(entryEl) # die, die stupid namespaces!!
        entry = copy.copy(emptyEntry)

        pm.taskCompleted()

        if int(entryEl.find("organism/dbReference").attrib["id"]) not in taxonIds:
            continue

        entryRow = parseRecInfo(entryEl, entry, isoSeqs)
        writeFaSeqs(entryRow, faFiles)
        writeFaSeqs(entryRow, varFaFiles, allVariants=True)

        entryOf.write("\t".join(entryRow)+"\n")
        recName = entryRow.name

        refRows = list(parseRefInfo(entryEl, recName))
        for refRow in refRows:
            refOf.write("\t".join(refRow)+"\n")

        mutRecs = parseVariants(entryEl, entryRow.mainIsoAcc)
        for mutRow in mutRecs:
            logging.debug("writing row %s" % str(mutRow))
            mutOf.write("\t".join(mutRow)+"\n")

        entryEl.clear()
    logging.info("Skipped annotation types: %s" % ignoredTypes.most_common())

def main(args, options):
    #logFname = join(outDir, "dbParse.log")
    if options.test:
        import doctest
        doctest.testmod()
        sys.exit(0)

    pubGeneric.setupLogging("", options)
    db = args[0]

    refDir = pubConf.dbRefDir
    maxCommon.mustExistDir(refDir, makeDir=True)

    if db=="pdb":
        dbDir = pubConf.pdbBaseDir
    elif db=="uniprot":
        dbDir = pubConf.uniProtBaseDir
    else:
        assert(False) # illegal db arg

    if db=="pdb":
        #parsePdb("/hive/data/outside/pdb/o9/pdb1o91.ent.gz", refDir)
        parsePdb(dbDir, refDir)
    elif db=="uniprot":
        taxonIds = set(pubConf.uniProtTaxonIds)
        parseUniprot(dbDir, refDir, taxonIds)


# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [options] pdb or uniprot - parse PDB or UniProt to tab-sep files

uniprot parser:
- goes over the disease comment evidences and tries to
  classify annotations as disease-related or not.  
- resolves disease codes to full disease names
- blacklists some PMIDs, annotations from these are skipped


""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages")
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="show more debug messages")
parser.add_option("-t", "--test", dest="test", action="store_true", help="run tests")
parser.add_option("-p", "--parse", dest="parse", action="store", help="parse a single uniprot xml file (debugging)")
(options, args) = parser.parse_args()

if args==[] and not options.test:
    parser.print_help()
    exit(1)

main(args, options)
