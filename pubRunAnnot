#!/usr/bin/env python2.7

# first load the standard libraries from python
# we require at least python 2.7
#from sys import *
import sys
if sys.version_info[0]==2 and not sys.version_info[1]>=7:
    print "Sorry, this program requires at least python 2.7"
    print "You can download a more current python version from python.org and compile it"
    print "into your homedir (or anywhere) with 'configure --prefix ~/python27'; make;"
    print "then run this program by specifying your own python executable like this: "
    print "   ~/python27/bin/python <scriptFile>"
    print "or add ~/python27/bin to your PATH before /usr/bin"
    exit(1)

# load default python packages
import logging, optparse, os, collections, tarfile, mimetypes, tempfile, \
    copy, shutil, glob, time
from os.path import *

# add <scriptDir>/lib/ to package search path
progFile = os.path.abspath(sys.argv[0])
progDir  = os.path.dirname(progFile)
pubToolsLibDir = os.path.join(progDir, "lib")
sys.path.insert(0, pubToolsLibDir)

# now load our own libraries
import maxRun, pubStore, pubConf, pubGeneric, protDetect, pubAlg
from maxCommon import *

# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [options] <algorithmName> <in> <outDir> <opt1>=<val1> <opt2>=<val2> ...- run an algorithm on a directory of fulltext files and write results to out directory

<in> can be a directory or dataset name:
- search <in> for fulltext chunks (*.articles.gz and *.files.gz)
- for each chunk submit a cluster job to write results to <out>

""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages") 
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="show more debug messages") 
parser.add_option("-r", "--runNow", dest="runNow", action="store_true", help="wait until jobs are all finished") 
parser.add_option("-t", "--test", dest="test", action="store_true", help="run locally in single process, not on cluster or multi processes, to see error messages, dump annotations to stdout") 
parser.add_option("", "--realTest", dest="realTest", action="store_true", help="spawn processes on local machine, like a cluster run, but error messages are visible, write annotations to final output files")
(options, args) = parser.parse_args()

# ==== FUNCTIONs =====
def checkCleanDir(outDir):
    mustExistDir(outDir)
    oldGzFiles = os.listdir(outDir)
    if len(oldGzFiles)>0:
        logging.info("Directory %s contains %d .gz files" % (outDir, len(oldGzFiles))
        logging.info("Waiting for 3 secs, then deleting them")
        time.sleep(3)
        pm = maxCommon.ProgressMeter(len(oldGzFiles))
        for oldGzFname in oldGzFiles:
            os.remove(join(outDir, oldGzFname))
            pm.taskCompleted()

# ----------- MAIN --------------
if args==[]: 
    parser.print_help()
    exit(1)

pubGeneric.setupLogging(progFile, options)

algName, inName, outName = args[:3]
runNow = options.runNow
paramStrings = args[3:]

paramDict = {}
paramDict = pubGeneric.stringListToDict(paramStrings)

alg = pubAlg.getAlg(algName) # makes sure that algName exists

paramDict["startAnnotId"] = 0

if options.test:
    reload(sys)
    sys.setdefaultencoding('utf-8')
    outName = "stdout"
    inDir = pubAlg.resolveTextDir(inName)
    inFiles = glob.glob(join(inDir, "*.articles.gz"))
    #inFiles = [inFiles[0]]

    for inFname in inFiles:
        logging.info("Running on %s" % inFname)
        reader = pubStore.PubReaderFile(inFname)
        pubAlg.runAnnotate(reader, alg, paramDict, outName)
else:
    checkCleanDir(outName)

    if options.realTest:
        runner = None
    else:
        runner = pubGeneric.makeClusterRunner(algName)
    pubAlg.annotate(algName, inName, paramDict, outName, runner=runner)
