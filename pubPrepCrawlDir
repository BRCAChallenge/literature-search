#!/usr/bin/env python

# load default python packages
import logging, optparse, os, sys, collections, gzip, re, codecs, operator, glob, random
from os.path import *

# add <scriptDir>/lib/ to package search path
sys.path.insert(0, join(dirname(abspath(__file__)),"lib"))

# load our own libraries
import pubConf, pubGeneric, tabfile, maxCommon, pubPubmed, pubResolvePublishers
from urllib2 import urlparse

import xml.etree.cElementTree as etree

# ===== FUNCTIONS =======

def parseIssns(journalDataDir, crawlPubDirs, crawlIssnOverwrite):
    " parse Issns into dict Issn, title -> pub "
    pubFname = join(journalDataDir, PUBLISHERTAB)
    logging.info("Parsing %s" % pubFname)
    pubs = maxCommon.iterTsvRows(pubFname)
    # parse into dict pub -> list of issns
    pubToIssn = {}
    issnToTitle = {}
    for pub in pubs:
        issns = pub.journalEIssns.split("|")
        titles = pub.titles.split("|")
        pubToIssn[pub.pubName] = (issns, titles)
        if len(titles)!=len(issns):
            logging.warn("Illegal fields for publisher %s, %s, %s" % (pub.pubName, pub.titles, pub.journalEIssns))
            continue
        assert(len(titles)==len(issns))
        for title, issn in zip(titles, issns):
            issnToTitle[issn] = title

    # check if all configured pubs are actually in this dict
    # write into dict issn -> pub
    issnToPub = {}
    for pubName in crawlPubDirs:
        if pubName not in pubToIssn:
            raise Exception("publisher %s defined in pubConf not found in %s" % (pubName, pubFname))
        issns, titles = pubToIssn[pubName]
        for issn, title in zip(issns, titles):
            issnToPub[issn] = pubName

    for corrIssn in crawlIssnOverwrite:
        if corrIssn in issnToPub:
            del issnToPub[corrIssn]

    # now reverse again and make dict pub -> set of (issn, title)
    pubToIssnName = {}
    for issn, pub in issnToPub.iteritems():
        pubToIssnName.setdefault(pub, set()).add((issn, issnToTitle.get(issn, "")))
    return pubToIssnName

def writeIssnTables(outDir, pubIds, pubToIssn, issnOverwrite):
    """ write (issn,minYear,maxYear) as issn.tab to all publisher directories, 
        adding issnOverwrite at the end 
    """
    outFhDict = {}

    # prep the lookup table
    pubIdToDescs = {}
    for pubDesc, pubId in pubIds.iteritems():
        pubIdToDescs.setdefault(pubId, []).append(pubDesc)

    # outDir has to be identical to the pubId from pubConf
    pubId = basename(outDir)

    issnOutFname = join(outDir, ISSNTAB)

    if not isdir(outDir):
        logging.info("Creating dir %s" % outDir)
        os.makedirs(outDir)

    # lookup Issns for publisher description
    # write default ISSNs
    logging.info("Writing to %s" % issnOutFname)
    if issnOutFname not in outFhDict:
        outFh = open(issnOutFname, "w")
        outFh.write("issn\tjournal\tstartYear\tendYear\tpublisher\n")
        outFhDict[issnOutFname] = outFh
    else:
        outFh = outFhDict[issnOutFname]
    issnCount = 0
    for pubDesc in pubIdToDescs[pubId]:
        for issn, title in pubToIssn[pubDesc]:
            if issn=="":
                continue
            outFh.write("%(issn)s\t%(title)s\t0\t0\t%(pubDesc)s\n" % locals())
            issnCount+=1

    # add manual ISSNs
    for issn, startYear, endYear in issnOverwrite.get(pubId, []):
        outFh.write("%s\t%d\t%d\t%s\n" % (issn, startYear, endYear, pubName))
        issnCount+=1
    logging.info("Wrote %d ISSNs" % issnCount)

def writeIssns(journalDataDir, outDir, pubDirs, issnOverwrite):
    """ use pubConf.py and the publishers.tab file to get target ISSNs
    and write them to outDir/issns.tab 
    """
    pubToIssnTitle = parseIssns(journalDataDir, pubDirs, issnOverwrite)
    writeIssnTables(outDir, pubDirs, pubToIssnTitle, issnOverwrite)

def writePmids(pubDir, pmids):
    " randomize pmids and write as pmids.txt to pubDir "
    random.shuffle(pmids)
    pmidFname = join(pubDir, "pmids.txt")
    logging.info("Writing %d PMIDs to %s" % (len(pmids), pmidFname))
    pmidFh = open(pmidFname, "w")
    for pmid in pmids:
        pmidFh.write(pmid+"\n")

def resolveIssnToPmid_Pubmed(issnRowFnames, minYear):
    """ use pubmed eutils to get the PMIDs for a dict of 
    pubDir -> (list of ISSN records) and append to filename """
    for pubDir, issns in issnRowFnames.iteritems():
        logging.info("Processing publisher dir %s" % pubDir)
        pmids = []
        for issnData in issns:
            # read pmids from pubmed or filesystem
            logging.info("Retrieving PMIDs for ISSN %s" % issnData.issn)
            query = issnData.issn+"[ta]"
            startYear = int(issnData.startYear)
            endYear = int(issnData.endYear)
            if startYear==0:
                startYear=str(minYear)
            if endYear==0:
                endYear="2030"
            query += " %s:%s[dp]" % (str(startYear), str(endYear))
            logging.debug("sending query to pubmed: %s" % query)
            
            issnPmids = list(pubPubmed.ncbiESearch(query, tool="pubtools_pubPrepCrawlDir", \
                email=pubConf.email, delaySecs=pubConf.eutilsDelaySecs))
            if len(issnPmids)==0:
                logging.warn("No PMIDs for pubmed query %s" % query)
            else:
                logging.info("Got %d PMIDs for ISSN %s" % (len(issnPmids), issnData.issn))
            pmids.extend(issnPmids)

        writePmids(pubDir, pmids)

             
def getPmidsForIssns(outDir, minYear):
    " look for issns.lst in outdir, download all PMIDs for these ISSNs and write to pmids.txt "
    #outDirFiles = glob.glob(join(outDir, "*"))
    outDirFiles = [outDir]

    # parse all issns into a big dict dirPath -> list of issns
    outDirIssns = {}
    for outDirPath in outDirFiles:
        if not isdir(outDirPath) or outDirPath.endswith(JOURNALDIR):
            logging.info("ignoring directory %s" % outDirPath)
            continue

        #if onlyDir!=None and onlyDir!=basename(outDirPath):
            #logging.info("Ignoring %s, onlyDir option set to %s" % (outDirPath, onlyDir))
            #continue

        issnFname = join(outDirPath, ISSNTAB)
        if not isfile(issnFname):
            logging.warn("Could not find %s" % issnFname)
            continue

        logging.info("Reading %s" % issnFname)

        for row in maxCommon.iterTsvRows(issnFname):
            outDirIssns.setdefault(outDirPath, []).append(row)

    resolveIssnToPmid_Pubmed(outDirIssns, minYear)

def main(args, options):
    pubGeneric.setupLoggingOptions(options)

    command = args[0]
    if len(args)>1:
        outDir = args[1]
    minYear = options.minYear
    #onlyDir = options.onlyDir

    pubDirs = pubConf.crawlPubIds
    issnOverwrite = pubConf.crawlIssnOverwrite

    #journalDataDir = join(outDir, JOURNALDIR)
    journalDataDir = pubConf.publisherDir
    #maxCommon.mustExistDir(journalDataDir, makeDir=True)
    maxCommon.mustExistDir(journalDataDir)

    command = command.lower()

    if command=="publishers":
        inDir = pubConf.journalListDir
        pubResolvePublishers.initJournalDir(inDir, journalDataDir, options.nlmCatalog)
    elif command=="issns":
        writeIssns(journalDataDir, outDir, pubDirs, issnOverwrite)
    elif command=="pmids":
        getPmidsForIssns(outDir, minYear)
    #elif command=="all":
        #writeIssns(journalDataDir, outDir, pubDirs, issnOverwrite)
        #getPmidsForIssns(outDir, minYear)
    else:
        raise Exception("Unknown command %s" % command)


# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [issns|pmids] <outDir> - prepare the directoriesy for the crawler filling it with ISSNs and PMIDs.

commands:
    %prog issns <outDir>      - create subdirectories under outDir and fill them 
                                with issn.tab files. resolve name of outDir to publisher using pubConf.

    %prog pmids <outDir>      - retrieve the PMIDs from Pubmed Eutils for all ISSNs in outDir

    usually not needed (internal data dir contains a list of publishers and their journals):
    %prog publishers          - re-create the list of publishers and their journals
""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages")
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="show more debug messages")
parser.add_option("", "--nlmCatalog", dest="nlmCatalog", action="store", help="use a given nlmCatalog.xml instead of the default one")
parser.add_option("-m", "--minYear", dest="minYear", action="store", type="int", help="minimum year for articles, default is %default", default=1990)
#parser.add_option("-o", "--onlyDir", dest="onlyDir", action="store", help="apply the PMID step only on a given directory")
(options, args) = parser.parse_args()

if len(args)<1:
    parser.print_help()
    exit(1)

main(args, options)
