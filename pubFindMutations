#!/usr/bin/env python

# load default python packages
import logging, optparse, sys, glob, gzip, gdbm, marshal
from os.path import join, basename, isfile, dirname, abspath, splitext, isdir
from collections import defaultdict, Counter, namedtuple

# I highly recommend installing re2, it's way faster than re
# we fallback to re just in case
#try:
    #import re2 as re
#except ImportError:
import re

# add <scriptDir>/lib/ to package search path
sys.path.insert(0, join(dirname(abspath(__file__)), "lib"))

import pubGeneric, maxCommon, pubConf, maxbio, pubAlg

mutFields = \
    (
    "patType",     # the type of the patterns (sub, del, ins)
    "seqType",     # the seqType of the patterns, dna or protein
    "protStart",   # the protein start position, if protein
    "protEnd",     # the protein end position, if protein
    "origAa",      # wild type amino acid seq
    "mutAa",       # mutated amino acid seq
    "texts",        # mutation match in text
    #"mutSupport",  # prot, dna, protDna
    #"mutCount",    # how often was this mutation mentioned?

    "geneSymbol",  # symbol of gene
    "entrezId",    # entrez ID of gene
    "protId",      # uniprot ID of protein
    "geneType",    # why was this gene selected (entrez, idInText, symInTitle, symInAbstract)
    "geneStarts",  # start positions of gene mentions in document
    "geneEnds",    # end positions of gene mentions in document

    "mutPatNames",    # the names of the patterns that matched, separated by |
    "mutStarts",   # start positions of mutation pattern matches in document
    "mutEnds",     # end positions of mutation pattern matches in document
    "mutSnippets",  # the phrases around the mutation mentions, separated by "|"
    "geneSnippets"  # the phrases around the gene mentions, separated by "|"
    )

# fields of the output file
MutRec = namedtuple("mutation_desc", mutFields)

threeToOne = \
    {'Cys': 'C', 'Asp': 'D', 'Ser': 'S', 'Gln': 'Q', 'Lys': 'K',
     'Ile': 'I', 'Pro': 'P', 'Thr': 'T', 'Phe': 'F', 'Asn': 'N', 
     'Gly': 'G', 'His': 'H', 'Leu': 'L', 'Arg': 'R', 'Trp': 'W', 
     'Ala': 'A', 'Val':'V',  'Glu': 'E', 'Tyr': 'Y', 'Met': 'M'}

blackList = [ 
    ("D", 11, "S"),
    ("D", 15, "S"),
    ("D", 16, "S")]
# ==== FUNCTIONS =====
def iterCommonFiles(inDirs, mask="*.tab.gz"):
    """ 
    yield lists of filenames that have the same name in all indirs 
    Doesn't really check if all dirs are identical.
    """
    fmask = join(inDirs[0], mask)
    for fname in glob.glob(fmask):
        base = basename(fname)
        flist = []
        for i in inDirs:
            dirFname = join(i, base)
            assert(isfile(dirFname))
            flist.append(dirFname)
        yield flist

def parseUniProt(inDir):
    " parse uniprot fa files and return as acc -> list of (isoformId, sequence) "
    faName = join(inDir, "uniprot.9606.var.fa.gz")
    seqs = maxbio.parseFastaAsDict(gzip.open(faName))

    result = defaultdict(list)
    for seqId, seq in seqs.iteritems():
        acc = seqId.split("-")[0]
        result[acc].append( (seqId, seq) )
    return result

def indexMuts(mutAnnots):
    mutCounts = Counter()
    mutToAnnots = defaultdict(list)
    for mut in mutAnnots:
        mutName = (int(mut.pos), mut.wtRes)
        #mutName = "".join((mut.wtRes, mut.pos, mut.mutRes))
        mutCounts.update([mutName])
        mutToAnnots[mutName].append(mut)
        extId = mut.externalId
        pmid = mut.pmid
    return extId, pmid, mutCounts, mutToAnnots

def indexGenes(upAnnots):
    """ given rows from annotation file, return extId, counts of uniprot accession and 
      dict with uniprot accession to list of annotations """
    upCounts = Counter()
    accToAnnots = defaultdict(list)
    assert(len(upAnnots)>0)
    extId = None
    for up in upAnnots:
        upCounts.update([up.uniProtAcc])
        accToAnnots[up.uniProtAcc].append(up)
        extId = up.externalId
    return extId, upCounts, accToAnnots

def findSeqs(seqs, accs, pos, res):
    " return all uniprot accessions from accs with at least one variant with residue at pos "
    matchSeqs = []
    for acc in accs:
        isoSeqs = seqs[acc]
        for seqId, seq in isoSeqs:
            if pos < len(seq) and seq[pos]==res:
                matchSeqs.append(seqId)
                break
    return matchSeqs

def someSnippets(idCounts, idToAnnots, isGene=False):
    """ create a list of descriptions for all ids in idCounts 
    also return a dict with id -> name
    """
    descs = []
    names = {}
    for id, count in idCounts.iteritems():
        annots = idToAnnots[id]
        annot = annots[0]
        if isGene:
            name = annot.word
        else:
            name = annot.wtRes+annot.pos+annot.mutRes
        names[id] = name
        descs.append("%s (%s, %d times): %s" % (id, name, count, annot.snippet))
    return descs, names

def parseRegex(mutDataDir):
    # read regexes and translate placeholders to long form
    replDict = {
    "sep"         : r"""(?:^|[\s\(\[\'"/,\-])""",
    "origAaShort" : r'(?P<origAaShort>[CISQMNPKDTFAGHLRWVEY])',
    "fromPos"     : r'(?P<fromPos>[1-9][0-9]+)',
    "toPos"       : r'(?P<toPos>[1-9][0-9]+)',
    "pos"         : r'(?P<pos>[1-9][0-9]+)',
    "mutAaShort"  : r'(?P<mutAaShort>[CISQMNPKDTFAGHLRWVEY])',
    "dna"         : r'(?P<dna>[actgACTG])',
    }
    regexTab = join(mutDataDir, "regex.txt")
    logging.info("Parsing regexes from %s" % regexTab)
    regexList = []
    counts = defaultdict(int)
    for row in maxCommon.iterTsvRows(regexTab):
        logging.debug("Translating %s" % row.pat)
        patName = row.pat
        patFull = row.pat.format(**replDict)
        regexList.append((row.seqType, row.mutType, patName, patFull))
        textComp = re.compile(patFull) # just checking
        counts[(row.seqType, row.mutType)] += 1

    for regexType, count in counts.iteritems():
            logging.info("regexType %s, Found %d regexes" % (str(regexType), count))
    return regexList

def openData(mutDataDir, taxId):
    " open db files, compile patterns, parse input as far as possible "
    fname = join(mutDataDir, "data.marshal")
    logging.info("Reading uniprot data from %s" % fname)
    data = marshal.load(open(fname))

    fname = join(mutDataDir, "pmid2entrez.dbm")
    logging.info("opening %s" % fname)
    pmid2entrez = gdbm.open(fname, "r")
    
    # parse regexes into list (seqType, mutType, patName, pat)
    regexes = parseRegex(mutDataDir)
    compRegexes = []
    for seqType, mutType, patName, pat in regexes:
        compRegexes.append( (seqType, mutType, patName, re.compile(pat)) )
        
    ret = {}
    ret["entrezToUp"] = data[taxId]["entrezToUp"]
    ret["upSeqs"] = data[taxId]["upSeqs"]
    ret["pmid2entrez"] = pmid2entrez
    ret["upToSym"] = data[taxId]["upToSym"]

    return ret, compRegexes

VariantFields = ["start", "end", "orig", "mut"]
Variant = namedtuple("Variant", VariantFields)
Mention = namedtuple("Mention", "patName,start,end")

def parseMatch(match, patName):
    groups = match.groupdict()
    # grab long and short versions of amino acid
    if "origAaShort" in groups:
        origAa = groups["origAaShort"]
    if "origAaLong" in groups:
        origAa = threeToOne[groups["origAaLong"]]

    if "mutAaShort" in groups:
        mutAa = groups["mutAaShort"]
    if "mutAaLong" in groups:
        mutAa = threeToOne[groups["mutAaLong"]]

    if "dna" in groups:
        origAa = groups["dna"]
        mutAa = ""

    if "fromPos" in groups:
        protStart = int(groups["fromPos"])
    if "toPos" in groups:
        protEnd = int(groups["toPos"])
    else:
        pos = int(groups["pos"])
        protStart = pos
        protEnd = pos+1

    var = Variant(protStart, protEnd, origAa, mutAa)

    start = match.start()
    end = match.end()
    mention = Mention(patName, start, end)

    if origAa==mutAa or (origAa, protStart, mutAa) in blackList:
        logging.debug("Variant is blacklisted")
        return None, None
    else:
        return var, mention

def findGenes(db, pmid, abstract, title, text):
    """ return dict where [entrez|title|abstract|text] = list of gene mentions 

    """
    geneTypes = {}
    if pmid in db["pmid2entrez"]:
        entrezGenes = db["pmid2entrez"][pmid].split(",")
        geneTypes["entrez"] = entrezGenes

    return geneTypes

def findMutations(regexes, text):
    """ put mutation mentions from document together into dicts indexed by normal form 
        return dict variant-> list of mentions
    """
    muts = defaultdict(list)
    for seqType, mutType, patName, pat in regexes:
        if mutType=="sub":
            for match in pat.finditer(text):
                variant, mention = parseMatch(match, patName)
                if variant!=None:
                    muts[variant].append(mention)
    return muts
    
class SeqVariant(object):
    " a variant grounded on a sequence, with pieces from the text "
    __slots__ = mutFields

    def __init__(self, mut, entrezGene, protId, geneSym, mentions, text):
        self.patType = "sub"
        self.seqType = "prot"
        self.protStart = mut.start
        self.protEnd   = mut.end
        self.origAa    = mut.orig
        self.mutAa    = mut.mut
        self.geneSymbol   = geneSym
        self.entrezId  = entrezGene
        self.protId    = protId
        self.geneType  = "entrez"
        self.geneStarts= ""
        self.geneEnds  = ""
        self.geneSnippets = ""

        mutStarts = []
        mutEnds = []
        snippets = []
        patNames = []
        texts = []
        for m in mentions:
            mutStarts.append(str(m.start))
            mutEnds.append(str(m.end))
            snippets.append(pubAlg.getSnippet(text, m.start, m.end).replace("|"," "))
            patNames.append(m.patName)
            texts.append(text[m.start:m.end].strip("() -;,."))

        self.mutStarts = ",".join(mutStarts)
        self.mutEnds   = ",".join(mutEnds)
        self.mutPatNames= "|".join(patNames)
        self.mutSnippets = "|".join(snippets)
        self.texts = "|".join(texts)

    def asRow(self):
        row =[]
        for i in self.__slots__:
            row.append(str(getattr(self, i)))
        return row
        
    def __repr__(self):
        return ",".join(self.asRow())
        
def ungroundedMutsToFakeSeqVariants(ungroundedMuts, text):
    """ convert mutations that could not be grounded to "fake" variants
        that not located on any sequence but are easy to write to a file
    """
    muts = []
    for mut, mentions in ungroundedMuts.iteritems():
        muts.append(SeqVariant(mut, "", "", "", mentions, text))
    return muts

def groundMutations(text, mutations, genes, geneData):
    """ ground mutations onto genes and return """
    groundedMuts = []
    ungroundedMuts = {}

    for mut, mentions in mutations.iteritems():
        logging.debug("Trying to ground mutation %s onto genes %s" % (mut, genes))
        entrezGenes = genes["entrez"]
        upStart = mut.start-1 # uniprot is 1-based, we are 0-based
        upEnd   = mut.end -1
        for entrezGene in entrezGenes:
            logging.debug("Trying entrez gene %s" % entrezGene)
            entrezId = int(entrezGene)
            if entrezId not in geneData["entrezToUp"]:
                logging.debug("gene %d is not selected species")
                continue
            protId = geneData["entrezToUp"][int(entrezGene)]
            geneSym = geneData["upToSym"][protId]
            seq = geneData["upSeqs"][protId]
            if not upEnd<=len(seq):
                logging.debug("sequence is too short")
                continue
                
            upAa = seq[upStart:upEnd]
            logging.debug("Found %s at pos %d-%d in uniprot %s" % (upAa, upStart, upEnd, protId))
            if upAa==mut.orig:
                groundedMuts.append(SeqVariant(mut, entrezGene, protId, geneSym, mentions, text))
            else:
                ungroundedMuts[mut] = mentions

    ungroundedMuts = ungroundedMutsToFakeSeqVariants(ungroundedMuts, text)
    return groundedMuts, ungroundedMuts

def writeHeaders(outFh):
    prefixHeaders = ["docId", "isConfirmed"]
    outFh.write("\t".join(prefixHeaders)+"\t"+"\t".join(mutFields)+"\n")

def writeMuts(docId, status, muts, outFh):
    for mut in muts:
        prefixFields=[docId, status]
        outFh.write("\t".join(prefixFields)+"\t")
        outFh.write("\t".join(mut.asRow()))
        outFh.write("\n")
    
def readFile(inFname):
    logging.info("Reading file %s" % inFname)
    text = open(inFname).read()
    title = ""
    abstract = ""
    pmid  = splitext(basename(inFname))[0]
    return pmid, title, abstract, text

def findInLocalFile(inFname, outFh, regexes, geneData):
    pmid, title, abstract, text = readFile(inFname)
    muts  = findMutations(regexes, text)
    genes = findGenes(geneData, pmid, title, abstract, text)
    if not "entrez" in genes:
        logging.info("Skipping %s" % inFname)
        return
    groundedMuts, ungroundMuts = groundMutations(text, muts, genes, geneData)
    writeMuts(pmid, "confirmed", groundedMuts, outFh)
    writeMuts(pmid, "notConfirmed", ungroundMuts, outFh)

def findInLocalDir(inDir, outFh, regexes, geneData):
    for fname in glob.glob(join(inDir, "*.txt")):
        logging.info(fname)
        findInLocalFile(fname, outFh, regexes, geneData)

def main(args, options):
    if options.test:
        import doctest
        doctest.testmod()
        sys.exit(0)

    pubGeneric.setupLogging("", options)
    mutDataDir = join(pubConf.staticDataDir, "mutFinder")

    inFname, outFname = args

    geneData, regexes = openData(mutDataDir, 9606)

    outFh = open(outFname, "w")
    writeHeaders(outFh)

    if isfile(inFname):
        findInLocalFile(inFname, outFh, regexes, geneData)
    elif isdir(inFname):
        findInLocalDir(inFname, outFh, regexes, geneData)
    else:
        assert(False)

    logging.info("Wrote output to %s" % outFname)
    outFh.close()


# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [options] annotDir - read geneSearcher and mutation_finderoutput, guess the gene for each mutation, and place onto uniprot sequences""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages")
parser.add_option("-v", "--verbose", dest="verbose", action="store_true", help="show more debug messages")
parser.add_option("-t", "--test", dest="test", action="store_true", help="run tests")
(options, args) = parser.parse_args()

if args==[] and not options.test:
    parser.print_help()
    exit(1)

pubGeneric.setupLogging(__file__, options)
main(args, options)
