#!/usr/bin/env python

# first load the standard libraries from python
# we require at least python 2.5
#from sys import *
import sys
if sys.version_info[0]==2 and not sys.version_info[1]>=7:
    print "Sorry, this program requires at least python 2.7"
    print "You can download a more current python version from python.org and compile it"
    print "into your homedir with 'configure --prefix ~/python'; make;"
    print "then run this program by specifying your own python executable like this: "
    print "   ~/python/bin/python ~/pubtools/pubtools"
    print "or add python/bin to your PATH before /usr/bin, then run pubtools itself"
    exit(1)

# load default python packages
import logging, optparse, os, glob, zipfile, types
from os.path import *

# add <scriptDir>/lib/ to package search path
progFile = os.path.abspath(sys.argv[0])
progDir  = os.path.dirname(progFile)
pubToolsLibDir = os.path.join(progDir, "lib")
sys.path.insert(0, pubToolsLibDir)

# now load our own libraries
import pubGeneric, maxRun, pubStore, pubConf, maxCommon, pubXml, pubPubmed

# load lxml parser, with fallback to default python parser
try:
    from lxml import etree # you can install this. Debian/Redhat package: python-lxml, see also: codespeak.net/lxml/installation.html
    import lxml
except ImportError:
    import xml.etree.cElementTree as etree # this is the slower, python2.5 default package

# === CONSTANTS ===================================
# === COMMAND LINE INTERFACE, OPTIONS AND HELP ===
parser = optparse.OptionParser("""usage: %prog [options] <inDir> <outDir> - convert medline .gz files to pubTools format

example:
pubConvMedline /hive/data/outside/literature/medline/ /hive/data/inside/literature/text/medline

Download from Medline with something like:
    lftp -e 'set net:socket-buffer 4000000; connect ftp://ftp.nlm.nih.gov/nlmdata/.medleasebaseline/gz; mirror -c --parallel=8 .; quit'
""")

parser.add_option("-d", "--debug", dest="debug", action="store_true", help="show debug messages") 
parser.add_option("", "--minId", dest="minId", action="store", help="numerical IDs written to the pubStore start at this number times one billion to prevent overlaps of numerical IDs between publishers, default %default", default=pubConf.identifierStart["medline"]) 
parser.add_option("", "--idsPerFile", dest="idsPerFile", action="store", help="reserver space for x entries in numerical namespace, default %default", default=500000) 
parser.add_option("", "--parse", dest="parse", action="store", help="for debugging, just parse one single xml file", default=None) 
(options, args) = parser.parse_args()

# ==== FUNCTIONs =====
def submitJobs(inDir, outDir, minId, idStep):
    chunkFiles = glob.glob(join(inDir, "*.gz"))
    if len(chunkFiles)==0:
        chunkFiles = glob.glob(join(inDir, "*.xml"))
    if len(chunkFiles)==0:
        logging.error("No gz or xml files found in %s" % inDir)
        sys.exit(1)

    runner = maxRun.Runner()
    chunkArticleId = minId
    chunkId = 0
    for chunkFname in chunkFiles:
        outFname = os.path.join(outDir, "%05d.articles.gz" % chunkId)
        maxCommon.mustNotExist(outFname)
        command = "%s %s {check in exists %s} {check out exists+ %s} %d" % (sys.executable, progFile, chunkFname, outFname, chunkArticleId)
        runner.submit(command)
        chunkArticleId += idStep
        chunkId += 1
    runner.finish()

def convertOneChunk(fileMinId, inFile, outFile):
    """ 
    convert one medlinefile to one pubtools file
    """ 
    store = pubStore.PubWriterFile(outFile)

    logging.debug("Reading %s" % inFile)
    if inFile.endswith(".gz"):
        xmlString = gzip.open(inFile).read()
    else:
        xmlString = open(inFile).read()
    #logging.debug("Parsing %s" % inFile)
    #xmlTree   = pubXml.etreeFromXml(xmlString)

    logging.debug("Writing to %s" % outFile)
    articleId = int(fileMinId)
    # parse & write to output
    for articleData in pubPubmed.parsePubmedArticleSet(xmlString, topTag="MedlineCitationSet"):
        logging.debug("Writing article %s" % str(articleId))
        articleData["source"]="medline"
        articleData["origFile"]=inFile
        store.writeArticle(articleId, articleData)
        articleId += 1
    store.close()

# ----------- MAIN --------------
# only for debugging
if options.parse!=None:
    fname = options.parse
    xmlString = open(fname).read()
    xmlTree   = pubXml.etreeFromXml(xmlString)
    for articleData in pubPubmed.parsePubmedArticleSet(xmlString, topTag="PubmedArticle"):
        for key, val in articleData.iteritems():
            print key, val.encode("utf8")
    sys.exit(0)
    
if args==[]: 
    parser.print_help()
    exit(1)

# normal operation
inDir, outDir = args[:2]
maxCommon.mustExist(inDir)

minId = options.minId
maxIdPerFile = options.idsPerFile

pubGeneric.setupLogging(progFile, options)

if os.path.isdir(inDir):
    maxCommon.mustExistDir(outDir)
    maxCommon.mustBeEmptyDir(outDir)
    submitJobs(inDir, outDir, minId, maxIdPerFile)
else:
    inFile = inDir
    outFile = outDir
    chunkMinId = args[2]
    convertOneChunk(int(chunkMinId), inFile, outFile)
